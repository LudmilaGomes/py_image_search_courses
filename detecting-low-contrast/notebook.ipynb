{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ea2719",
   "metadata": {},
   "source": [
    "# [Detecting low contrast images with OpenCV, scikit-image, and Python](https://pyimagesearch.com/2021/01/25/detecting-low-contrast-images-with-opencv-scikit-image-and-python/)\n",
    "\n",
    "If you are able to control the environment and, most importantly, the lighting when you capture an image, the easier it will be to write code to process the image. But is'nt possible to always controll your environment and lighting conditions.\n",
    "\n",
    "In this cases, you can instead detect when low quality images, specifically low contrast images, are presented to your pipeline. And then, if a low contrast image is detected, you can throw the image out or alert the user to capture an image in better lighting conditions.\n",
    "\n",
    "## Problems that low contrast images create in computer vision scenarios\n",
    "\n",
    "A low contrast image has very little difference between light and dark regions, making it hard to see where the boundary of an object begins and the background of the scene starts (due to poor lighting conditions (i.e., not enough light), the boundaries of the card against the background are not well defined).\n",
    "\n",
    "In this moments, you cannot control the lighting conditions and any parameters hard-coded in the pipeline may result in incorrect output.\n",
    "\n",
    "So, using low contrast image detection, you can programmatically detect images that are not sufficient for your image processing pipeline. Weâ€™ll throw out images/frames that are low contrast and not suitable for our pipeline, while keeping only the ones that we know will produce usable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc523767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b4f8247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851deaf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b57995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.exposure import is_low_contrast\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80f282b",
   "metadata": {},
   "source": [
    "`threshold` parameter default is `0.35`, which means that if less than 35% of the range of brightness occupies the full range of the data type, then the image is considered low contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b6bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/ludmila/.local/lib/python3.10/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "path_image = 'image.png'\n",
    "\n",
    "image = cv2.imread(path_image)\n",
    "image = imutils.resize(image, width=450)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# blur the image slightly and perform edge detection\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(blurred, 30, 150)\n",
    "\n",
    "# initialize the text and color to indicate that the input image is not low contrast\n",
    "text = \"Low contrast: No\"\n",
    "color = (0, 255, 0)\n",
    "\n",
    "if is_low_contrast(gray, fraction_threshold=0.35):\n",
    "  # update the text and color\n",
    "  text = \"Low contrast: Yes\"\n",
    "  color = (0, 0, 255)\n",
    "\n",
    "# otherwise, the image is not low contrast, so we can continue processing it\n",
    "else:\n",
    "  # find contours in the edge map and find the largest one,\n",
    "  # which we'll assume is the outline of our color correction\n",
    "  # card\n",
    "  cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  cnts = imutils.grab_contours(cnts)\n",
    "  c = max(cnts, key=cv2.contourArea)\n",
    "  # draw the largest contour on the image\n",
    "  cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "\n",
    "# draw the text on the output image\n",
    "cv2.putText(image, text, (5, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "# show the output image and edge map\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edge\", edged)\n",
    "cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
