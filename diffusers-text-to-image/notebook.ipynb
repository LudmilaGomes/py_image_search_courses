{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f433fc9d",
   "metadata": {},
   "source": [
    "# [Getting Started with Diffusers for Text-to-Image](https://pyimagesearch.com/2024/01/22/getting-started-with-diffusers-for-text-to-image/)\n",
    "\n",
    "Using Diffusers library from Hugging Face, we'll generate images from text.\n",
    "\n",
    "Diffusion Models are generative models, meaning that they are used to generate data similar to the data on which they are trained. These models work by destroying training data through the successive addition of Gaussian noise and then learning to recover the data by reversing this noising process.\n",
    "\n",
    "Diffusion probabilistic models are parameterized Markov chains trained to gradually denoise data. \n",
    "\n",
    "<!-- O modelo inicialmente é treinado para adicionar ruído nas imagens. Após isso, ele faz o processo inverso, retirando a imagem adicionada e reconstruindo-a.\n",
    "A partir disso, o modelo de difusão aprende a gerar imagens (estas baseadas nas usadas no seu treinamento) com base em ruído. -->\n",
    "\n",
    "- What we'll use: The Diffusers library, developed by Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1686735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5ddae8",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b8d383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-08 14:45:43.448172: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-08 14:45:43.638955: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754675143.714626   19528 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754675143.744619   19528 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754675143.909264   19528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754675143.909291   19528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754675143.909293   19528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754675143.909294   19528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-08 14:45:43.926750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import diffusers\n",
    "from PIL import Image\n",
    "from diffusers import UNet2DModel\n",
    "from diffusers import AutoPipelineForText2Image\n",
    "from diffusers import DDPMPipeline\n",
    "from diffusers import DDPMScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449e5bf6",
   "metadata": {},
   "source": [
    "## Diffusers\n",
    "\n",
    "- Model: determine the residual noise;\n",
    "- Scheduler: it's a noise scheduling algorithm (define how many diffusion steps are needed for inference);\n",
    "- Pipeline: it amalgamates a model with a scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1f20ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c115e244f34e89912e4bae298dc5d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a12954b0394da7868743f496eb1b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7f7331b52e4eea8e47402b5ffbe579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9340d98f27b47bb9ec73c2fed7681db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7054f409658542b196b99dfea0ca844a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fe753809624facacf50ae597a428e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b5b4dda78f4cb4b8e96f9b3aacea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61468822907c45488c78cd2548dcbbc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a736177f4cd446a8de009de6d4600a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/model.fp16.safetensors:   0%|          | 0.00/608M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14cc3ed4cf144deba99cd51cb25612f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model.fp16.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3e13674c57425682aa62d109684071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61987593e51b43268880e07d8a41e605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca5d4e2950f4b22b1f653c66bdc7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8747a9ff6214ea781541905305b4dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5637c80d20e64ad5a228d8952f3eb457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/diffusion_pytorch_model.fp16.safete(…):   0%|          | 0.00/1.72G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87f6614c03448b1806e0a8c4a27ac25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/diffusion_pytorch_model.fp16.safeten(…):   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b953020f6b94cdd828995ff5a4a6e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# automatically discern the most suitable pipeline class for a task\n",
    "pipeline = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16, variant=\"fp16\").to(\"cuda\")\n",
    "\n",
    "# tests with\n",
    "# stabilityai/stable-diffusion-xl-base-1.0\n",
    "# kandinsky-community/kandinsky-2-2-decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccfaa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0bd01b8c7c440e907484aa1c2e61de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = pipeline(\"impressionist oil painting of pikachu, backlight, centered composition, masterpiece, photorealistic, 8k\").images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = \"Astronaut in a 1700 New York, cold color palette, muted colors, detailed, 8k\"\n",
    "\n",
    "# image = pipeline(prompt = prompt, height=768, width=512).images[0]\n",
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e92a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for flexibility accommodating to specific user needs \n",
    "\n",
    "# image = pipeline(prompt,\n",
    "#                  height=768,\n",
    "#                  width=512,\n",
    "#                  num_inference_steps=70,\n",
    "#                  guidance_scale=10.5,\n",
    "#                  ).images[0]\n",
    "# image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6634a423",
   "metadata": {},
   "source": [
    "## Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "- Model\n",
    "  - Instances of the model class are neural networks that take a noisy sample as well as a timestep as inputs to predict a less noisy output sample.\n",
    "\n",
    "- Schedulers\n",
    "  - Act as the algorithmic backbone that guides both the training and inference processes (it dictates how noise is added to the model; after this, they take the model output, typically the noisy_residual, and compute a slightly less noisy sample from it).\n",
    "    - Unlike models, which have trainable weights, schedulers usually do not possess any trainable parameters.\n",
    "    - Despite not inheriting from torch.nn.Module like typical neural network models, schedulers are still instantiated based on a configuration.\n",
    "- [DDPM Paper](https://arxiv.org/abs/2006.11239)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
