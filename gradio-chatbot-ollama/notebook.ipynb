{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "802e00c5",
   "metadata": {},
   "source": [
    "## [Creating a chatbot with Gradio, Llama 3.2 and Ollama API](https://pyimagesearch.com/2025/02/10/building-a-multimodal-gradio-chatbot-with-llama-3-2-using-the-ollama-api/)\n",
    "\n",
    "- Gradio: enables create user-friendly and interactive web applications and simplifies create ML workflow\n",
    "  - Multimodal support\n",
    "  - Easily integrates with APIs (Ollama!)\n",
    "\n",
    "---\n",
    "\n",
    "- Ollama: enables run LLMs locally\n",
    "  - Local execution\n",
    "  - Model management\n",
    "  - Two ways to interact: Restful APIs calls and Python clien\n",
    "\n",
    "1. \n",
    "\n",
    "```python\n",
    "\n",
    "curl http://localhost:11434/api/generate -d '{\n",
    "  \"model\": \"llama3.2\",\n",
    "  \"prompt\": \"Describe the Eiffel Tower.\"\n",
    "}'\n",
    "```\n",
    "\n",
    "2. \n",
    "\n",
    "```python\n",
    "import ollama\n",
    "# Initialize the client\n",
    "client = ollama.Client()\n",
    "# Send a chat request\n",
    "response = client.chat(\n",
    "    model=\"llama3.2\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Describe the Eiffel Tower.\"}\n",
    "    ]\n",
    ")\n",
    "# Print the response\n",
    "print(response['message']['content'])\n",
    "```\n",
    "\n",
    "- You can store LLMs on your local machine efficiently with Ollama in `~/.ollama/models`\n",
    "- Pull models `ollama pull llama3.2-vision`\n",
    "- `ollama list`\n",
    "- `ollama remove llama3.2-vision`\n",
    "- Ollama allows redirecting model storage to a different directory\n",
    "\n",
    "--- \n",
    "\n",
    "- Llama3.2 (Meta) enables processing both text and images\n",
    "  - Multimodal processing\n",
    "  - Variants: 11B and 90B\n",
    "    - Smaller variants are optimized to run locally!\n",
    "  - What it cand do: Visual Question Answering (VQA), Image Captioning, Visual Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c42222",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Versions: `ollama==0.3.3`, `pillow==11.0.0 (PIL)`, and `gradio==5.5.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "48841c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gradio==5.5.0 in /home/ludmila/.local/lib/python3.10/site-packages (5.5.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.6.1)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.34.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (2.2.6)\n",
      "Requirement already satisfied: orjson~=3.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (3.11.1)\n",
      "Requirement already satisfied: packaging in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (2.10.4)\n",
      "Requirement already satisfied: pydub in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/lib/python3/dist-packages (from gradio==5.5.0) (5.4.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.12.7)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.46.1)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.15.2)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio==5.5.0) (0.34.0)\n",
      "Requirement already satisfied: fsspec in /home/ludmila/.local/lib/python3.10/site-packages (from gradio-client==1.4.2->gradio==5.5.0) (2024.9.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /home/ludmila/.local/lib/python3.10/site-packages (from gradio-client==1.4.2->gradio==5.5.0) (12.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ludmila/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.5.0) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5.0,>=3.0->gradio==5.5.0) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ludmila/.local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio==5.5.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ludmila/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==5.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<3.0,>=1.0->gradio==5.5.0) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ludmila/.local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio==5.5.0) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ludmila/.local/lib/python3.10/site-packages (from pydantic>=2.0->gradio==5.5.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ludmila/.local/lib/python3.10/site-packages (from pydantic>=2.0->gradio==5.5.0) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/ludmila/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.5.0) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/ludmila/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.5.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/ludmila/.local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio==5.5.0) (13.9.4)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.24.1->gradio==5.5.0) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ludmila/.local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio==5.5.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ludmila/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==5.5.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (3.15.4)\n",
      "Requirement already satisfied: requests in /home/ludmila/.local/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ludmila/.local/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (4.66.5)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ludmila/.local/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio==5.5.0) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio==5.5.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ludmila/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.5.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ludmila/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.5.0) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/ludmila/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.5.0) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ludmila/.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio==5.5.0) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->huggingface-hub>=0.25.1->gradio==5.5.0) (1.26.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio==5.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0188d33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pillow==11.0.0 in /home/ludmila/.local/lib/python3.10/site-packages (11.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow==11.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44e6c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: ollama==0.3.3 in /home/ludmila/.local/lib/python3.10/site-packages (0.3.3)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /home/ludmila/.local/lib/python3.10/site-packages (from ollama==0.3.3) (0.27.2)\n",
      "Requirement already satisfied: anyio in /home/ludmila/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama==0.3.3) (4.8.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx<0.28.0,>=0.27.0->ollama==0.3.3) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ludmila/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama==0.3.3) (1.0.7)\n",
      "Requirement already satisfied: idna in /usr/lib/python3/dist-packages (from httpx<0.28.0,>=0.27.0->ollama==0.3.3) (3.3)\n",
      "Requirement already satisfied: sniffio in /home/ludmila/.local/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama==0.3.3) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ludmila/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama==0.3.3) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ludmila/.local/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama==0.3.3) (1.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /home/ludmila/.local/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama==0.3.3) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama==0.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5513dbe",
   "metadata": {},
   "source": [
    "## Setting up the utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bea583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "# converts a PIL.Image object into a byte stream\n",
    "def image_to_bytes(image):\n",
    "  buffered = io.BytesIO()\n",
    "  image.save(buffered, format=\"JPEG\")\n",
    "  return buffered.getvalue()\n",
    "\n",
    "# why? APIs like Ollama require images to be sent as byte data instead of Python objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08622bf1",
   "metadata": {},
   "source": [
    "## Chatbot logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a79eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'point point21321 point point'.strip('point point')\n",
    "# '21321'\n",
    "\n",
    "# '       a        '.strip()\n",
    "# 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65b43610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "class ChatBot:\n",
    "  def __init__(self, model_name, retries):\n",
    "    self.client = ollama.Client()\n",
    "    self.model_name = model_name\n",
    "    self.retries = retries # nº retry attempts in case of API request failures\n",
    "    self.history = []\n",
    "\n",
    "  def add_user_message(self, text_input, image_input, response_style):\n",
    "    message = {'role': 'user', 'content': text_input.strip()}\n",
    "    \n",
    "    if response_style == \"Detailed\":\n",
    "      message['content'] += \" Please provide a detailed response.\"\n",
    "    elif response_style == \"Concise\":\n",
    "      message['content'] += \" Keep the response concise.\"\n",
    "    self.history.append(message)\n",
    "\n",
    "  def generate_response(self):\n",
    "    for attempt in range(self.retries):\n",
    "      response = self.client.chat(model=self.model_name, messages=self.history)\n",
    "\n",
    "      assistant_message = {'role': 'assistant', 'content': response['message']['content']}\n",
    "      return assistant_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23fb39e",
   "metadata": {},
   "source": [
    "## Interface - Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "MODEL_NAME = 'llama3.2-vision'\n",
    "chatbot = ChatBot(MODEL_NAME, 5)\n",
    "\n",
    "def handle_user_input(text_input, image_input, response_style):\n",
    "  if not text_input and not image_input:\n",
    "    return (\"Please provide either text or an image.\", \n",
    "            \"\\n\".join(f\"{msg['role'].capitalize()}: {msg['content']}\" for msg in chatbot.history))\n",
    "  \n",
    "  try:\n",
    "    generated_text = chatbot.generate_response()\n",
    "    return generated_text, chatbot.history\n",
    "  except Exception as e:\n",
    "    return (f\"An error occurred: {str(e)}\", \n",
    "            \"\\n\".join([f\"{msg['role'].capitalize()}: {msg['content']}\" for msg in chatbot.history]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ac115c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ludmila/.local/lib/python3.10/site-packages/gradio/analytics.py:108: UserWarning: unable to parse version details from package URL.\n",
      "  warnings.warn(\"unable to parse version details from package URL.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Could not create share link. Missing file: /home/ludmila/.local/lib/python3.10/site-packages/gradio/frpc_linux_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_linux_amd64\n",
      "2. Rename the downloaded file to: frpc_linux_amd64_v0.3\n",
      "3. Move the file to this location: /home/ludmila/.local/lib/python3.10/site-packages/gradio\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "  gr.Markdown(\"# Enhanced Multimodal Chatbot with Llama 3.2 Vision\")\n",
    "  gr.Markdown(\"Upload an image or enter a text prompt, choose a response style, and view the generated response along with the interaction history.\")\n",
    "  \n",
    "  with gr.Row():\n",
    "      text_input = gr.Textbox(lines=2, placeholder=\"Enter your question here...\", label=\"Text Input\")\n",
    "      image_input = gr.Image(type=\"pil\", label=\"Image Input (Optional)\")\n",
    "      response_style = gr.Dropdown([\"Detailed\", \"Concise\", \"Creative\"], label=\"Response Style\", value=\"Detailed\")\n",
    "    \n",
    "      with gr.Column():\n",
    "        generated_response = gr.Textbox(label=\"Generated Response\")\n",
    "  \n",
    "  submit_button = gr.Button(\"Submit\")\n",
    "  \n",
    "  submit_button.click(\n",
    "      fn=handle_user_input,\n",
    "      inputs=[text_input, image_input, response_style],\n",
    "      outputs=generated_response\n",
    "  )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
